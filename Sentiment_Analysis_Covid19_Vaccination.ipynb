{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Installing a tweet preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXsMYNIJU_Jv"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install tweet-preprocessor  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importing the python libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLW9jzoCS4o9"
      },
      "outputs": [],
      "source": [
        "!pip install gensim --upgrade\n",
        "!pip install pyldavis\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "from gensim.models import Word2Vec\n",
        "from wordcloud import WordCloud\n",
        "from google.colab import drive\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from textblob import TextBlob                         \n",
        "from textblob import Word\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_validate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importing the python libraries  to read the csv file from the drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eOHjhGCU2vO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import preprocessor as p\n",
        "drive.mount('/content/drive')   #mounting the drive\n",
        "path = '/content/drive/MyDrive/Tweet_Covid19.csv'   \n",
        "df = pd.read_csv(path)  #reading the csv file where our tweet data is saved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YkFShXSUK3i"
      },
      "outputs": [],
      "source": [
        "#displaying the first few rows of dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2By1R7XURj6"
      },
      "outputs": [],
      "source": [
        "\n",
        "#here we are cleaing the text data and checking if there are any unwanted data\n",
        "#before we generate the sentiment from the text\n",
        "\n",
        "def preprocess_tweet(row):\n",
        "    tweet = row['text']\n",
        "    tweet = p.clean(text)\n",
        "    return tweet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importing TextBlob library for the sentiment analysis on text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5z4HniXVWGQ"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "df['polarity'] = df['text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "df['subjectivity'] = df['text'].apply(lambda x: TextBlob(x).sentiment.subjectivity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmaoMaf1ViQT"
      },
      "outputs": [],
      "source": [
        "#getting analysis by getAnalysis method \n",
        "\n",
        "from textblob import TextBlob\n",
        "def getAnalysis(score):\n",
        "   if score < 0:\n",
        "    return 'Negative'\n",
        "   elif score == 0:\n",
        "     return 'Neutral'\n",
        "   else:\n",
        "     return 'Positive'\n",
        "df['sentiment'] = df['polarity'].apply(getAnalysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JH-jyoN_VyOU"
      },
      "outputs": [],
      "source": [
        "#displaying the first few rows of the dataset after the sentiment analysis on text\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhUm3yL-WpuX"
      },
      "outputs": [],
      "source": [
        "#listing all the columns present in a dataset\n",
        "list(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAr2y7oTWvkb"
      },
      "outputs": [],
      "source": [
        "#checking for null values and dropping them\n",
        "#displaying the sentiments using histogram\n",
        "df.isnull().values.any()\n",
        "df = df.dropna()\n",
        "df['sentiment'].hist(bins=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hOq4QHTW815"
      },
      "outputs": [],
      "source": [
        "#removing stop words, punctuations and converting into lowercase \n",
        "#Keep only lowercase characters from the text column to remove noise, removing links\n",
        "df['text'] = df['text'].replace('[^a-zA-Z]', ' ',regex=True).str.lower()\n",
        "df['text'] = df['text'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop = stopwords.words('english')\n",
        "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "df['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCaz9bLvW_qg"
      },
      "outputs": [],
      "source": [
        "#Finding most common words from the corpus and common words for each sentiment\n",
        "#Using word cloud we are graphically representing the word frequency for each sentiment.\n",
        "df['sentiment'].hist(bins=10)\n",
        "# Globally\n",
        "total_wordcloud = WordCloud().generate(' '.join(df['text']))\n",
        "plt.imshow(total_wordcloud), plt.title('Most common words')\n",
        "plt.show()\n",
        "# Per sentiment\n",
        "pos_df = df[df['sentiment'] == 'Positive']\n",
        "neu_df = df[df['sentiment'] == 'Neutral']\n",
        "neg_df = df[df['sentiment'] == 'Negative']\n",
        "\n",
        "pos_wordcloud = WordCloud().generate(' '.join(pos_df['text']))\n",
        "neu_wordcloud = WordCloud().generate(' '.join(neu_df['text']))\n",
        "neg_wordcloud = WordCloud().generate(' '.join(neg_df['text']))\n",
        "\n",
        "plt.imshow(pos_wordcloud), plt.title('Most common words (positive sentiment)'),plt.show()\n",
        "plt.imshow(neu_wordcloud), plt.title('Most common words (neutral sentiment)'),plt.show()\n",
        "plt.imshow(neg_wordcloud), plt.title('Most common words (negative sentiment)'),plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snOXUztqXTOH"
      },
      "outputs": [],
      "source": [
        "#comparing the snetiments between diefferent vaccines that are occuring in the source text(astrazeneca-pfizer-moderna)\n",
        "astra_df = df[df['text'].str.contains('astrazeneca')]\n",
        "moderna_df = df[df['text'].str.contains('moderna')]\n",
        "pfizer_df = df[df['text'].str.contains('pfizer') | df['text'].str.contains('biontech')]\n",
        "\n",
        "plt.hist(astra_df['sentiment']), plt.title('AstraZeneca sentiments'), plt.show()\n",
        "plt.hist(moderna_df['sentiment']), plt.title('Moderna sentiments'), plt.show()\n",
        "plt.hist(pfizer_df['sentiment']), plt.title('Pfizer sentiments'), plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1MM-LzGXi9E"
      },
      "outputs": [],
      "source": [
        "#checking average number of user friends per sentiment.\n",
        "pos_friends = df[df['sentiment']=='Positive']['user_friends'].astype(int)\n",
        "neg_friends = df[df['sentiment']=='Negative']['user_friends'].astype(int)\n",
        "pos_friends.mean(), neg_friends.mean()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDKZNWStZMwv"
      },
      "outputs": [],
      "source": [
        "#Subsampling the dataframe and checking the performance\n",
        "print(len(df[df['sentiment'] == 'Neutral']), len(df[df['sentiment'] == 'Positive']), len(df[df['sentiment'] == 'Negative']))\n",
        "df = df.sample(frac=1)\n",
        "subsampled_df = df[df['sentiment'] == 'Neutral'][:int(0.15*len(df))]\n",
        "print('Subsampled dataframe with neutral sentiments length: ', len(subsampled_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating Train and Test Dataset on Sentiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI5BvafTZ-5U"
      },
      "outputs": [],
      "source": [
        "#creating the train/test dataset on negative and positive sentiment and\n",
        "#concating the two data frames subsamples and sentiment data frames.\n",
        "\n",
        "combined_df = pd.concat([subsampled_df,df[df['sentiment'] == 'Negative'], df[df['sentiment'] == 'Positive']])\n",
        "combined_df = combined_df[['text', 'sentiment']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_df['text'], combined_df['sentiment'], test_size=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vectorization: Bag of words/Tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCU3a7TOaGjk"
      },
      "outputs": [],
      "source": [
        "bow_vectorizer = CountVectorizer()\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_test_bow = bow_vectorizer.transform(X_test)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Word2Vec "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDaGm9x8aQD1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create Word2Vec representation.\n",
        "print('Training Word2Vec model (after tokenization)...')\n",
        "tokenized_X_train = [nltk.word_tokenize(tweet) for tweet in X_train]\n",
        "tokenized_X_test = [nltk.word_tokenize(tweet) for tweet in X_test]\n",
        "# Learn word vectors from the corpus, dimensionality is 100\n",
        "model = Word2Vec(tokenized_X_train, vector_size=100, window=5, min_count=5, workers=4)\n",
        "model.train(tokenized_X_train, total_examples=len(tokenized_X_train), epochs=5)\n",
        "X_train_w2v = []\n",
        "print('Transforming train tweets to w2v representation...')\n",
        "\n",
        "for tweet in tokenized_X_train:\n",
        "    if len(tweet) > 0:\n",
        "        text = [word for word in tweet if word in model.wv.key_to_index]\n",
        "    else:\n",
        "        text = ['empty']\n",
        "    # Take the average of each vector\n",
        "    w2v_tweet = np.mean(model.wv[text], axis=0)\n",
        "    X_train_w2v.append(w2v_tweet)\n",
        "  \n",
        "# Sanity check and conversion to numpy array\n",
        "print('Processed this number of tweets: ', len(X_train_w2v))\n",
        "X_train_w2v = np.array(X_train_w2v)\n",
        "print('Train corpus shape after word2vec conversion', X_train_w2v.shape)\n",
        "# Also transform the test set for usage later on\n",
        "X_test_w2v = []\n",
        "for tweet in tokenized_X_test:\n",
        "    if len(tweet) > 0:\n",
        "        text = [word for word in tweet if word in model.wv.key_to_index]\n",
        "    else:\n",
        "        text = ['empty']\n",
        "    # Take the average of each vector\n",
        "    w2v_news = np.mean(model.wv[text], axis=0)\n",
        "    X_test_w2v.append(w2v_news)\n",
        "\n",
        "# Sanity check and conversion to numpy array\n",
        "print('Processed this number of tweets: ', len(X_test_w2v))\n",
        "X_test_w2v = np.array(X_test_w2v)\n",
        "print('Test corpus shape after word2vec conversion', X_test_w2v.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8qsU6Xxl5Em"
      },
      "source": [
        "LDA topic modelling: Lemmatization -> stemming -> bag of works (tokenization and stopword removal have already been performed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzPM8t8kaSeX"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(tokenized_X_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification with SVM, RandomForests and KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdbNILktaX9l"
      },
      "outputs": [],
      "source": [
        "\n",
        "scoring = {'Accuracy': 'accuracy', 'Precision': 'precision_macro', 'Recall': 'recall_macro',\n",
        "           'F-Measure': 'f1_macro'}\n",
        "n_jobs = -1\n",
        "\n",
        "def train_evaluate_classifier(corpus, sentiments, clf):\n",
        "    if clf == 'svm':\n",
        "        # Train SVM and evaluate with 10fold\n",
        "        # Dual = False helps speed up the process\n",
        "        print('Training SVM classifier...')\n",
        "        svm_clf = LinearSVC(dual=False)\n",
        "        svm_score = cross_validate(svm_clf, corpus, sentiments, cv=10, scoring=scoring, n_jobs=n_jobs, verbose=10)\n",
        "        return svm_score\n",
        "    elif clf == 'random_forest':\n",
        "        print('Training Random Forest Classifier...')\n",
        "        forest_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=n_jobs, verbose=10)\n",
        "        forest_score = cross_validate(forest_clf, corpus, sentiments, cv=10, scoring=scoring, n_jobs=n_jobs, verbose=10)\n",
        "        return forest_score\n",
        "    elif clf == 'knn':\n",
        "        # Custom method using ridge classifier\n",
        "        # After multiple tests, this turned out to be the most successful one metrics-wise\n",
        "        # Some preprocessing is also done here, by using stop words to remove irrelevant words from the vocabulary\n",
        "        print('Training KNN classifier')\n",
        "        knn_clf = KNeighborsClassifier(n_jobs=n_jobs)\n",
        "        knn_clf.fit(corpus, sentiments)\n",
        "        knn_clf_score = cross_validate(knn_clf, corpus, sentiments, cv=10, scoring=scoring,\n",
        "                                         n_jobs=n_jobs,\n",
        "                                         verbose=10)\n",
        "        return knn_clf_score\n",
        "\n",
        "def format_results(score_list):\n",
        "    results = []\n",
        "    for clf_score in score_list:\n",
        "        clf_results = {'Accuracy': float(\"{0:.4f}\".format(np.mean(clf_score['test_Accuracy']))),\n",
        "                       'Precision': float(\"{0:.4f}\".format(np.mean(clf_score['test_Precision']))),\n",
        "                       'Recall': float(\"{0:.4f}\".format(np.mean(clf_score['test_Recall']))),\n",
        "                       'F-Measure': float(\"{0:.4f}\".format(np.mean(clf_score['test_F-Measure'])))}\n",
        "        results.append(clf_results)\n",
        "    return results\n",
        "\n",
        "def predict(corpus, clf):\n",
        "    print('Predicting on test set...')\n",
        "    predictions = clf.predict(corpus)\n",
        "    return predictions\n",
        "\n",
        "classifiers = ['svm', 'random_forest', 'knn']\n",
        "corpus_dict = {'bow': X_train_bow, 'tfidf': X_train_tfidf, 'w2v': X_train_w2v}\n",
        "# Train, evaluate classifiers and format results properly\n",
        "scores = []\n",
        "combinations = list(itertools.product(corpus_dict.values(), classifiers))\n",
        "for current_corpus, classifier in combinations:\n",
        "    scores.append(train_evaluate_classifier(current_corpus, y_train, classifier))\n",
        "\n",
        "\n",
        "\n",
        "formatted_scores = format_results(score_list=scores)\n",
        "\n",
        "print('Results from 10fold cross-validation on the training set')\n",
        "result_combinations = ['SVM-bow', 'SVM-tfidf', 'SVM-w2v', 'Random Forest-bow', 'Random Forest-tfidf', 'Random Forest w2v',\n",
        "                       'KNN-bow', 'KNN-tfidf', 'KNN-w2v']\n",
        "\n",
        "for result_combination, current_result in zip(result_combinations, formatted_scores):\n",
        "    print(result_combination, current_result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
